{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Keras笑脸识别\n",
    "本部分的任务是读取图片并识别图片上的**笑脸**。\n",
    "Keras是一个比Tensorflow层次更高的框架，一般来说通用的模型都可以通过Keras实现，但是一些复杂的模型在keras中没有，只能用较低层次的Tensorflow或pytorch实现\n",
    "#### 1.1 引入库 and 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 600\n",
      "number of test examples = 150\n",
      "X_train shape: (600, 64, 64, 3)\n",
      "Y_train shape: (600, 1)\n",
      "X_test shape: (150, 64, 64, 3)\n",
      "Y_test shape: (150, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "import kt_utils \n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# 加载数据\n",
    "X_train_orig,Y_train_orig,X_test,Y_test,classes = kt_utils.load_dataset()\n",
    "X_train = X_train_orig / 255\n",
    "Y_train = Y_train_orig / 255\n",
    "\n",
    "Y_train = Y_train_orig.T\n",
    "Y_test = Y_test.T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 使用keras框架构建训练模型\n",
    "keras与tensorflow不一样的是，我们不需要创建如Z1,A1等的中间变量，只需要保存最后结果，所以在fp的时候只有一个tensor X。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "        input_shape - 输入参数的size\n",
    "    返回：\n",
    "        model - keras模型\n",
    "    \"\"\"\n",
    "    # 类似于tensorflow中的创建占位符\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # zero padding\n",
    "    # 由于后面我们要用到7*7的卷积 所以这里p=(7-1)/2=3\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "    \n",
    "    # Conv - BN - relu\n",
    "    X = Conv2D(32,(7,7),strides=(1,1),name=\"conv0\")(X)\n",
    "    X = BatchNormalization(axis=3,name=\"bn0\")(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # MaxPooling\n",
    "    X = MaxPooling2D((2,2),name=\"max_pool\")(X)\n",
    "    \n",
    "    # 向量化\n",
    "    X = Flatten()(X)\n",
    "    # Fully Connected\n",
    "    X = Dense(1,activation=\"sigmoid\",name=\"fc\")(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name=\"HappyModel\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 2.0804 - acc: 0.5817\n",
      "Epoch 2/60\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.6351 - acc: 0.7817\n",
      "Epoch 3/60\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.3815 - acc: 0.8483\n",
      "Epoch 4/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.3199 - acc: 0.8850\n",
      "Epoch 5/60\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.2238 - acc: 0.9200\n",
      "Epoch 6/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.1241 - acc: 0.9600\n",
      "Epoch 7/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.1171 - acc: 0.9633\n",
      "Epoch 8/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0948 - acc: 0.9650\n",
      "Epoch 9/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0899 - acc: 0.9717\n",
      "Epoch 10/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0709 - acc: 0.9817\n",
      "Epoch 11/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0715 - acc: 0.9800\n",
      "Epoch 12/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0632 - acc: 0.9867\n",
      "Epoch 13/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0699 - acc: 0.9850\n",
      "Epoch 14/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0796 - acc: 0.9733\n",
      "Epoch 15/60\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0574 - acc: 0.9833\n",
      "Epoch 16/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0543 - acc: 0.9833\n",
      "Epoch 17/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 18/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0338 - acc: 0.9950\n",
      "Epoch 19/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 20/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0368 - acc: 0.9883\n",
      "Epoch 21/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0324 - acc: 0.9933\n",
      "Epoch 22/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0286 - acc: 0.9933\n",
      "Epoch 23/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 24/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0309 - acc: 0.9933\n",
      "Epoch 25/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0272 - acc: 0.9967\n",
      "Epoch 26/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0279 - acc: 0.9967\n",
      "Epoch 27/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0236 - acc: 0.9950\n",
      "Epoch 28/60\n",
      "600/600 [==============================] - 12s 20ms/step - loss: 0.0239 - acc: 0.9967\n",
      "Epoch 29/60\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0248 - acc: 0.9950\n",
      "Epoch 30/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0191 - acc: 0.9950\n",
      "Epoch 31/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0192 - acc: 0.9967\n",
      "Epoch 32/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0167 - acc: 0.9967\n",
      "Epoch 33/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0185 - acc: 0.9967\n",
      "Epoch 34/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0231 - acc: 0.9950\n",
      "Epoch 35/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0185 - acc: 0.9967\n",
      "Epoch 36/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0186 - acc: 0.9967\n",
      "Epoch 37/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0141 - acc: 0.9983\n",
      "Epoch 38/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0186 - acc: 0.9933\n",
      "Epoch 39/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0190 - acc: 0.9967\n",
      "Epoch 40/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0162 - acc: 0.9967\n",
      "Epoch 41/60\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0143 - acc: 0.9950\n",
      "Epoch 42/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0131 - acc: 0.9967\n",
      "Epoch 43/60\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0171 - acc: 0.9933\n",
      "Epoch 44/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0163 - acc: 0.9950\n",
      "Epoch 45/60\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0128 - acc: 0.9967\n",
      "Epoch 46/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 47/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0115 - acc: 0.9967\n",
      "Epoch 48/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0132 - acc: 0.9967\n",
      "Epoch 49/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0083 - acc: 0.9967\n",
      "Epoch 50/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0075 - acc: 0.9983\n",
      "Epoch 51/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0089 - acc: 0.9983\n",
      "Epoch 52/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 53/60\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0070 - acc: 0.9983\n",
      "Epoch 54/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0090 - acc: 0.9983\n",
      "Epoch 55/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0078 - acc: 0.9983\n",
      "Epoch 56/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0069 - acc: 0.9967\n",
      "Epoch 58/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0074 - acc: 0.9983\n",
      "Epoch 59/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0137 - acc: 0.9950\n",
      "Epoch 60/60\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0079 - acc: 0.9983\n",
      "150/150 [==============================] - 1s 8ms/step\n",
      "Error:5.951823825836182\n",
      "Accuracy:0.6266666674613952\n"
     ]
    }
   ],
   "source": [
    "# 获取模型\n",
    "HappyModel = model(X_train.shape[1:])\n",
    "\n",
    "# 编译模型\n",
    "HappyModel.compile(\"adam\",\"binary_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "HappyModel.fit(X_train,Y_train,epochs=60,batch_size=50)\n",
    "\n",
    "# 评估模型\n",
    "preds = HappyModel.evaluate(X_test,Y_test,batch_size=32,verbose=1,sample_weight=None)\n",
    "print(\"Error:\"+str(preds[0]))\n",
    "print(\"Accuracy:\"+str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 70, 70, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 64, 64, 32)        4736      \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pool (MaxPooling2D)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 1)                 32769     \n",
      "=================================================================\n",
      "Total params: 37,633\n",
      "Trainable params: 37,569\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 利用summary函数观察网络结构\n",
    "HappyModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
